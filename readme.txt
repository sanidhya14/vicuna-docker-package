1. Clone repo: git clone https://github.com/fredi-python/llama.cpp.git
2. Download vicuna model to: /vicuna-13B-model from: wget https://huggingface.co/eachadea/ggml-vicuna-13b-1.1/resolve/main/ggml-vic13b-uncensored-q5_1.bin
3. Build docker container & run it !

Credits: https://github.com/vicuna-tools/vicuna-installation-guide
